import os
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
import time
from tqdm import tqdm
import torch

import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config import TRACKING_CONFIG, PATH_CONFIG, LANE_CONFIG

class VehicleTracker:
    def __init__(self, model_path="/home/lumos/Documents/yolo11x.pt", vehicle_classes=None, conf_threshold=None):
        """è½¦è¾†è½¨è¿¹è·Ÿè¸ªå™¨"""
        
        # ä½¿ç”¨é…ç½®å‚æ•°æˆ–é»˜è®¤å€¼
        self.model_path = model_path or TRACKING_CONFIG['model_path']
        self.vehicle_classes = vehicle_classes or TRACKING_CONFIG['vehicle_classes']
        self.conf_threshold = conf_threshold or TRACKING_CONFIG['conf_threshold']
        self.lane_config = LANE_CONFIG
        self.lane_boundaries = self.lane_config.get('boundaries', [])
        self.lane_labels = self.lane_config.get('labels', [])
        self.lane_mode = self.lane_config.get('mode', 'relative')
        self.lane_fallback = self.lane_config.get('fallback_label', 'unknown')
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = YOLO(self.model_path)
        self.trajectories = {}
        
        # æ£€æŸ¥GPU
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def process_video(self, video_path, output_path=None, skip_frames=1, target_fps=None):
        """
        å¤„ç†è§†é¢‘å¹¶æå–è½¨è¿¹ - ä¿®å¤æ—¶é—´è®¡ç®—é—®é¢˜
        """
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if output_path:
            output_dir = os.path.dirname(output_path)
            os.makedirs(output_dir, exist_ok=True)
            
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        # è·å–è§†é¢‘ä¿¡æ¯
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / original_fps if original_fps > 0 else 0
        
        print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {frame_width}x{frame_height}, FPS: {original_fps:.1f}, æ€»å¸§æ•°: {total_frames}, æ—¶é•¿: {duration/60:.1f}åˆ†é’Ÿ")
        
        # ä¿®å¤ï¼šç¡®ä¿FPSä¸ä¸ºé›¶
        if original_fps <= 0:
            print("âš ï¸ è§†é¢‘FPSå¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤å€¼30")
            original_fps = 30.0
        
        # è®¡ç®—å¤„ç†å¸§æ•°
        processed_frames = (total_frames + skip_frames) // (skip_frames + 1)
        print(f"âš¡ å¤„ç†è®¾ç½®: è·³å¸§={skip_frames}, é¢„è®¡å¤„ç† {processed_frames} å¸§")
        
        # åˆå§‹åŒ–è½¨è¿¹æ•°æ®å­˜å‚¨
        trajectory_data = []
        frame_count = 0
        processed_count = 0
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=processed_frames, desc="å¤„ç†è§†é¢‘å¸§")
        start_time = time.time()
        
        # æ€§èƒ½ç»Ÿè®¡
        performance_stats = {
            'frames_processed': 0,
            'vehicles_detected': 0,
            'processing_times': []
        }
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            # è·³å¸§å¤„ç†
            if frame_count % (skip_frames + 1) != 0:
                frame_count += 1
                continue
                
            if processed_count >= processed_frames:
                break
            
            # è°ƒæ•´å›¾åƒå°ºå¯¸ä»¥æé«˜å¤„ç†é€Ÿåº¦
            target_width = 640
            if frame_width > target_width:
                scale_factor = target_width / frame_width
                new_width = target_width
                new_height = int(frame_height * scale_factor)
                frame_resized = cv2.resize(frame, (new_width, new_height))
                width_scale = frame_width / new_width
                height_scale = frame_height / new_height
            else:
                frame_resized = frame
                width_scale = 1.0
                height_scale = 1.0
            
            frame_processing_start = time.time()
            
            # è¿è¡ŒYOLOæ£€æµ‹
            results = self.model.track(
                frame_resized, 
                persist=True,
                classes=self.vehicle_classes,
                conf=self.conf_threshold,
                iou=TRACKING_CONFIG['iou_threshold'],
                verbose=False,
                tracker="bytetrack.yaml"
            )
            
            if results[0].boxes is not None and results[0].boxes.id is not None:
                # ç›´æ¥ä»YOLOç»“æœä¸­æå–æ£€æµ‹ä¿¡æ¯ï¼ˆä¸éœ€è¦supervisionåº“ï¼‰
                boxes = results[0].boxes
                
                # è·å–æ‰€æœ‰æ£€æµ‹æ¡†çš„ä¿¡æ¯
                track_ids = boxes.id.cpu().numpy().astype(int)  # è·Ÿè¸ªID
                bboxes = boxes.xyxy.cpu().numpy()  # è¾¹ç•Œæ¡†åæ ‡ [x1, y1, x2, y2]
                class_ids = boxes.cls.cpu().numpy().astype(int)  # ç±»åˆ«ID
                confidences = boxes.conf.cpu().numpy()  # ç½®ä¿¡åº¦
                
                # éå†æ¯ä¸ªæ£€æµ‹ç»“æœ
                for i in range(len(track_ids)):
                    track_id = track_ids[i]
                    bbox = bboxes[i]  # [x1, y1, x2, y2]
                    class_id = class_ids[i]
                    confidence = confidences[i]
                    
                    # è®¡ç®—è½¦è¾†ä¸­å¿ƒç‚¹å’Œè¾¹ç•Œæ¡†åæ ‡
                    if width_scale != 1.0 or height_scale != 1.0:
                        # è¿˜åŸåˆ°åŸå§‹å°ºå¯¸çš„åæ ‡
                        bbox_x1 = bbox[0] * width_scale
                        bbox_y1 = bbox[1] * height_scale
                        bbox_x2 = bbox[2] * width_scale
                        bbox_y2 = bbox[3] * height_scale
                        center_x = ((bbox[0] + bbox[2]) / 2) * width_scale
                        center_y = ((bbox[1] + bbox[3]) / 2) * height_scale
                        bbox_width = (bbox[2] - bbox[0]) * width_scale
                        bbox_height = (bbox[3] - bbox[1]) * height_scale
                    else:
                        bbox_x1 = bbox[0]
                        bbox_y1 = bbox[1]
                        bbox_x2 = bbox[2]
                        bbox_y2 = bbox[3]
                        center_x = (bbox[0] + bbox[2]) / 2
                        center_y = (bbox[1] + bbox[3]) / 2
                        bbox_width = bbox[2] - bbox[0]
                        bbox_height = bbox[3] - bbox[1]
                    
                    # ä¿®å¤ï¼šæ­£ç¡®è®¡ç®—æ—¶é—´æˆ³
                    # ä½¿ç”¨ frame_count è€Œä¸æ˜¯ processed_count æ¥è®¡ç®—æ—¶é—´
                    current_time = frame_count / original_fps
                    lane_label = self._assign_lane(center_x, frame_width)
                    
                    # å­˜å‚¨è½¨è¿¹æ•°æ®ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
                    trajectory_point = {
                        'frame_id': frame_count,
                        'time': current_time,  # æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
                        'track_id': track_id,  # è½¦è¾†è·Ÿè¸ªID
                        'x': center_x,  # ä¸­å¿ƒç‚¹Xåæ ‡ï¼ˆåƒç´ ï¼‰
                        'y': center_y,  # ä¸­å¿ƒç‚¹Yåæ ‡ï¼ˆåƒç´ ï¼‰
                        'bbox_x1': bbox_x1,  # è¾¹ç•Œæ¡†å·¦ä¸Šè§’Xåæ ‡
                        'bbox_y1': bbox_y1,  # è¾¹ç•Œæ¡†å·¦ä¸Šè§’Yåæ ‡
                        'bbox_x2': bbox_x2,  # è¾¹ç•Œæ¡†å³ä¸‹è§’Xåæ ‡
                        'bbox_y2': bbox_y2,  # è¾¹ç•Œæ¡†å³ä¸‹è§’Yåæ ‡
                        'width': bbox_width,  # è¾¹ç•Œæ¡†å®½åº¦ï¼ˆåƒç´ ï¼‰
                        'height': bbox_height,  # è¾¹ç•Œæ¡†é«˜åº¦ï¼ˆåƒç´ ï¼‰
                        'class_id': class_id,  # COCOç±»åˆ«ID
                        'vehicle_type': self._get_vehicle_type(class_id),  # è½¦è¾†ç±»å‹ï¼ˆcar/bus/truck/motorcycleï¼‰
                        'confidence': confidence,  # æ£€æµ‹ç½®ä¿¡åº¦
                        'lane': lane_label  # è½¦é“ä¿¡æ¯
                    }
                    trajectory_data.append(trajectory_point)
                    performance_stats['vehicles_detected'] += 1
            
            processed_count += 1
            frame_count += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.update(1)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            frame_processing_time = time.time() - frame_processing_start
            performance_stats['processing_times'].append(frame_processing_time)
            
            # æ¯å¤„ç†50å¸§æ›´æ–°ä¸€æ¬¡æ€§èƒ½ä¿¡æ¯
            if processed_count % 50 == 0:
                elapsed_time = time.time() - start_time
                current_fps = processed_count / elapsed_time
                avg_processing_time = np.mean(performance_stats['processing_times'][-50:])
                current_progress_minutes = frame_count / original_fps / 60
                
                pbar.set_postfix({
                    'fps': f'{current_fps:.1f}',
                    'vehicles': len(trajectory_data),
                    'frame_time': f'{avg_processing_time:.2f}s',
                    'progress': f'{current_progress_minutes:.1f}min'
                })
        
        pbar.close()
        cap.release()
        
        # æ€§èƒ½ç»Ÿè®¡æ€»ç»“
        total_time = time.time() - start_time
        actual_fps = processed_count / total_time if total_time > 0 else 0
        final_time_minutes = frame_count / original_fps / 60
        
        print(f"âœ… å¤„ç†å®Œæˆ!")
        print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"   - æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"   - å¤„ç†å¸§æ•°: {processed_count}")
        print(f"   - å®é™…å¸§ç‡: {actual_fps:.1f} FPS")
        print(f"   - æ£€æµ‹åˆ°è½¨è¿¹ç‚¹: {len(trajectory_data)}")
        print(f"   - å®é™…å¤„ç†æ—¶é•¿: {final_time_minutes:.1f} åˆ†é’Ÿ")
        if performance_stats['processing_times']:
            print(f"   - å¹³å‡æ¯å¸§å¤„ç†æ—¶é—´: {np.mean(performance_stats['processing_times']):.3f}ç§’")
        
        # è½¬æ¢ä¸ºDataFrame
        if len(trajectory_data) == 0:
            print("âš ï¸ è­¦å‘Š: æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•è½¦è¾†è½¨è¿¹æ•°æ®")
            return pd.DataFrame()
        
        trajectories_df = pd.DataFrame(trajectory_data)
        
        # æ•°æ®éªŒè¯å’Œç»Ÿè®¡
        unique_vehicles = trajectories_df['track_id'].nunique()
        total_points = len(trajectories_df)
        time_range = trajectories_df['time'].max() - trajectories_df['time'].min()
        
        print(f"\nğŸ“Š è½¨è¿¹æ•°æ®ç»Ÿè®¡:")
        print(f"   - æ€»è½¨è¿¹ç‚¹æ•°: {total_points}")
        print(f"   - å”¯ä¸€è½¦è¾†æ•°: {unique_vehicles}")
        print(f"   - æ—¶é—´èŒƒå›´: {trajectories_df['time'].min():.2f} - {trajectories_df['time'].max():.2f} ç§’ ({time_range:.2f}ç§’)")
        print(f"   - å¹³å‡æ¯è½¦è½¨è¿¹ç‚¹: {total_points / unique_vehicles:.1f}" if unique_vehicles > 0 else "   - å¹³å‡æ¯è½¦è½¨è¿¹ç‚¹: 0")
        
        # è½¦è¾†ç±»å‹ç»Ÿè®¡
        if 'vehicle_type' in trajectories_df.columns:
            vehicle_type_counts = trajectories_df['vehicle_type'].value_counts()
            print(f"   - è½¦è¾†ç±»å‹åˆ†å¸ƒ:")
            for vtype, count in vehicle_type_counts.items():
                print(f"     {vtype}: {count} ä¸ªè½¨è¿¹ç‚¹")
        
        # ä¿å­˜è½¨è¿¹æ•°æ®åˆ°CSVæ–‡ä»¶
        if output_path:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)
            
            # æŒ‰åˆ—é¡ºåºä¿å­˜ï¼ˆç¡®ä¿åˆ—çš„é¡ºåºä¸€è‡´ï¼‰
            column_order = [
                'frame_id', 'time', 'track_id',
                'x', 'y',
                'bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2',
                'width', 'height',
                'class_id', 'vehicle_type', 'lane', 'confidence'
            ]
            
            # åªä¿å­˜å­˜åœ¨çš„åˆ—
            existing_columns = [col for col in column_order if col in trajectories_df.columns]
            trajectories_df[existing_columns].to_csv(
                output_path, 
                index=False,
                encoding='utf-8-sig'  # ä½¿ç”¨UTF-8 BOMç¼–ç ï¼Œç¡®ä¿Excelå¯ä»¥æ­£ç¡®æ‰“å¼€ä¸­æ–‡
            )
            
            print(f"\nğŸ’¾ è½¨è¿¹æ•°æ®å·²ä¿å­˜è‡³: {output_path}")
            print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
            print(f"   - æ•°æ®åˆ—æ•°: {len(existing_columns)}")
            print(f"   - æ•°æ®è¡Œæ•°: {len(trajectories_df)}")
            
            # ä¿å­˜æ•°æ®æ‘˜è¦ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            summary_path = output_path.replace('.csv', '_summary.txt')
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write("=" * 60 + "\n")
                f.write("è½¨è¿¹æ•°æ®æ‘˜è¦ä¿¡æ¯\n")
                f.write("=" * 60 + "\n\n")
                f.write(f"è§†é¢‘ä¿¡æ¯:\n")
                f.write(f"  - åˆ†è¾¨ç‡: {frame_width}x{frame_height}\n")
                f.write(f"  - å¸§ç‡: {original_fps:.2f} FPS\n")
                f.write(f"  - æ€»å¸§æ•°: {total_frames}\n")
                f.write(f"  - æ—¶é•¿: {duration/60:.2f} åˆ†é’Ÿ\n\n")
                f.write(f"å¤„ç†è®¾ç½®:\n")
                f.write(f"  - è·³å¸§æ•°: {skip_frames}\n")
                f.write(f"  - å¤„ç†å¸§æ•°: {processed_count}\n")
                f.write(f"  - ç½®ä¿¡åº¦é˜ˆå€¼: {self.conf_threshold}\n\n")
                f.write(f"è½¨è¿¹æ•°æ®ç»Ÿè®¡:\n")
                f.write(f"  - æ€»è½¨è¿¹ç‚¹æ•°: {total_points}\n")
                f.write(f"  - å”¯ä¸€è½¦è¾†æ•°: {unique_vehicles}\n")
                f.write(f"  - æ—¶é—´èŒƒå›´: {trajectories_df['time'].min():.2f} - {trajectories_df['time'].max():.2f} ç§’\n")
                f.write(f"  - æ—¶é—´è·¨åº¦: {time_range:.2f} ç§’ ({time_range/60:.2f} åˆ†é’Ÿ)\n")
                if unique_vehicles > 0:
                    f.write(f"  - å¹³å‡æ¯è½¦è½¨è¿¹ç‚¹: {total_points / unique_vehicles:.1f}\n")
                f.write(f"\nè½¦è¾†ç±»å‹åˆ†å¸ƒ:\n")
                if 'vehicle_type' in trajectories_df.columns:
                    for vtype, count in vehicle_type_counts.items():
                        f.write(f"  - {vtype}: {count} ä¸ªè½¨è¿¹ç‚¹ ({count/total_points*100:.1f}%)\n")
                f.write(f"\næ€§èƒ½ç»Ÿè®¡:\n")
                f.write(f"  - æ€»è€—æ—¶: {total_time:.1f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)\n")
                f.write(f"  - å®é™…å¸§ç‡: {actual_fps:.1f} FPS\n")
                if performance_stats['processing_times']:
                    f.write(f"  - å¹³å‡æ¯å¸§å¤„ç†æ—¶é—´: {np.mean(performance_stats['processing_times']):.3f} ç§’\n")
            
            print(f"ğŸ“„ æ•°æ®æ‘˜è¦å·²ä¿å­˜è‡³: {summary_path}")
        
        return trajectories_df
    
    def process_video_fast(self, video_path, output_path=None):
        """å¿«é€Ÿå¤„ç†æ¨¡å¼ - é’ˆå¯¹é•¿è§†é¢‘ä¼˜åŒ–"""
        # åˆ›å»ºä¸´æ—¶trackerå®ä¾‹ï¼Œä½¿ç”¨æ›´é«˜çš„ç½®ä¿¡åº¦é˜ˆå€¼
        fast_tracker = VehicleTracker(
            model_path=self.model_path,
            vehicle_classes=self.vehicle_classes,
            conf_threshold=0.2  # ä½¿ç”¨æ›´é«˜çš„ç½®ä¿¡åº¦é˜ˆå€¼
        )
        
        return fast_tracker.process_video(
            video_path=video_path,
            output_path=output_path,
            skip_frames=0  # æ›´é«˜çš„è·³å¸§
        )
    
    def process_video_balanced(self, video_path, output_path=None):
        """å¹³è¡¡å¤„ç†æ¨¡å¼"""
        # åˆ›å»ºä¸´æ—¶trackerå®ä¾‹ï¼Œä½¿ç”¨é€‚ä¸­çš„å‚æ•°
        balanced_tracker = VehicleTracker(
            model_path=self.model_path,
            vehicle_classes=self.vehicle_classes,
            conf_threshold=0.1  # é€‚ä¸­çš„ç½®ä¿¡åº¦é˜ˆå€¼
        )
        
        return balanced_tracker.process_video(
            video_path=video_path,
            output_path=output_path,
            skip_frames=1  # é€‚ä¸­çš„è·³å¸§
        )
    
    def _get_vehicle_type(self, class_id):
        """å°†ç±»åˆ«IDæ˜ å°„ä¸ºè½¦è¾†ç±»å‹"""
        vehicle_map = {
            2: 'car',
            3: 'motorcycle', 
            5: 'bus',
            7: 'truck'
        }
        return vehicle_map.get(class_id, 'other')
    
    def _assign_lane(self, center_x, frame_width):
        """æ ¹æ®ä¸­å¿ƒç‚¹Xåæ ‡åˆ¤æ–­æ‰€åœ¨è½¦é“"""
        if not self.lane_boundaries or not self.lane_labels:
            return self.lane_fallback
        
        if len(self.lane_boundaries) != len(self.lane_labels) + 1:
            return self.lane_fallback
        
        if self.lane_mode == 'relative':
            if frame_width <= 0:
                return self.lane_fallback
            position = center_x / frame_width
        else:
            position = center_x
        
        for idx, label in enumerate(self.lane_labels):
            start = self.lane_boundaries[idx]
            end = self.lane_boundaries[idx + 1]
            if start <= position < end:
                return label
        
        return self.lane_labels[-1] if self.lane_labels else self.lane_fallback
    
    def generate_annotated_video(self, video_path, trajectories_df, output_video_path=None, 
                                 show_track_id=True, show_vehicle_type=True, show_confidence=True):
        """
        ç”Ÿæˆæ ‡æ³¨è§†é¢‘ï¼Œåœ¨è§†é¢‘ä¸Šæ˜¾ç¤ºæ£€æµ‹æ¡†ã€è·Ÿè¸ªIDã€è½¦è¾†ç±»å‹ç­‰ä¿¡æ¯
        
        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            trajectories_df: è½¨è¿¹æ•°æ®DataFrame
            output_video_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨ç”Ÿæˆï¼‰
            show_track_id: æ˜¯å¦æ˜¾ç¤ºè·Ÿè¸ªID
            show_vehicle_type: æ˜¯å¦æ˜¾ç¤ºè½¦è¾†ç±»å‹
            show_confidence: æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
        
        Returns:
            è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        
        if trajectories_df.empty:
            print("âš ï¸ è½¨è¿¹æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆæ ‡æ³¨è§†é¢‘")
            return None
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if output_video_path is None:
            video_dir = os.path.dirname(video_path)
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            output_video_path = os.path.join(video_dir, f"{video_name}_annotated.mp4")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_video_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        print(f"\nğŸ¬ å¼€å§‹ç”Ÿæˆæ ‡æ³¨è§†é¢‘...")
        print(f"   è¾“å…¥è§†é¢‘: {video_path}")
        print(f"   è¾“å‡ºè§†é¢‘: {output_video_path}")
        
        # æ‰“å¼€è¾“å…¥è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return None
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        # å°è¯•ä½¿ç”¨H.264ç¼–ç ï¼ˆæ›´å¥½çš„å‹ç¼©ç‡å’Œå…¼å®¹æ€§ï¼‰ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨mp4v
        fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264ç¼–ç 
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
        
        if not out.isOpened():
            print(f"âš ï¸ H.264ç¼–ç ä¸å¯ç”¨ï¼Œä½¿ç”¨mp4vç¼–ç ...")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
            if not out.isOpened():
                print(f"âŒ æ— æ³•åˆ›å»ºè§†é¢‘æ–‡ä»¶: {output_video_path}")
                cap.release()
                return None
        
        # è½¦è¾†ç±»å‹é¢œè‰²æ˜ å°„
        vehicle_colors = {
            'car': (0, 255, 0),        # ç»¿è‰²
            'bus': (255, 0, 0),         # è“è‰²
            'truck': (0, 0, 255),      # çº¢è‰²
            'motorcycle': (255, 255, 0), # é’è‰²
            'other': (128, 128, 128)    # ç°è‰²
        }
        
        # æŒ‰å¸§åˆ†ç»„è½¨è¿¹æ•°æ®
        trajectories_by_frame = {}
        for _, row in trajectories_df.iterrows():
            frame_id = int(row['frame_id'])
            if frame_id not in trajectories_by_frame:
                trajectories_by_frame[frame_id] = []
            trajectories_by_frame[frame_id].append(row)
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(total=total_frames, desc="ç”Ÿæˆæ ‡æ³¨è§†é¢‘")
        
        frame_count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # åœ¨å½“å‰å¸§ä¸Šç»˜åˆ¶æ ‡æ³¨
            if frame_count in trajectories_by_frame:
                for _, vehicle in enumerate(trajectories_by_frame[frame_count]):
                    # è·å–è½¦è¾†ä¿¡æ¯
                    track_id = int(vehicle['track_id'])
                    bbox_x1 = int(vehicle['bbox_x1'])
                    bbox_y1 = int(vehicle['bbox_y1'])
                    bbox_x2 = int(vehicle['bbox_x2'])
                    bbox_y2 = int(vehicle['bbox_y2'])
                    vehicle_type = vehicle['vehicle_type']
                    confidence = vehicle['confidence']
                    
                    # è·å–è½¦è¾†é¢œè‰²
                    color = vehicle_colors.get(vehicle_type, (128, 128, 128))
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(frame, (bbox_x1, bbox_y1), (bbox_x2, bbox_y2), color, 2)
                    
                    # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
                    label_parts = []
                    if show_track_id:
                        label_parts.append(f"ID:{track_id}")
                    if show_vehicle_type:
                        label_parts.append(vehicle_type)
                    if show_confidence:
                        label_parts.append(f"{confidence:.2f}")
                    
                    label = " ".join(label_parts)
                    
                    # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆåœ¨è¾¹ç•Œæ¡†ä¸Šæ–¹ï¼‰
                    (text_width, text_height), baseline = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
                    )
                    text_x = bbox_x1
                    text_y = max(bbox_y1 - 5, text_height)
                    
                    # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯ï¼ˆåŠé€æ˜ï¼‰
                    cv2.rectangle(
                        frame,
                        (text_x, text_y - text_height - 5),
                        (text_x + text_width, text_y + baseline),
                        color,
                        -1
                    )
                    
                    # ç»˜åˆ¶æ–‡æœ¬
                    cv2.putText(
                        frame,
                        label,
                        (text_x, text_y),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        (255, 255, 255),  # ç™½è‰²æ–‡å­—
                        1,
                        cv2.LINE_AA
                    )
            
            # åœ¨è§†é¢‘å·¦ä¸Šè§’æ·»åŠ å¸§ä¿¡æ¯
            info_text = f"Frame: {frame_count} | Time: {frame_count/fps:.2f}s"
            cv2.putText(
                frame,
                info_text,
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
                cv2.LINE_AA
            )
            
            # å†™å…¥å¸§
            out.write(frame)
            frame_count += 1
            pbar.update(1)
        
        pbar.close()
        cap.release()
        out.release()
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_video_path):
            file_size = os.path.getsize(output_video_path) / 1024 / 1024
            print(f"\nâœ… æ ‡æ³¨è§†é¢‘ç”Ÿæˆå®Œæˆ!")
            print(f"   - è¾“å‡ºæ–‡ä»¶: {output_video_path}")
            print(f"   - æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            print(f"   - åˆ†è¾¨ç‡: {width}x{height}")
            print(f"   - å¸§ç‡: {fps:.2f} FPS")
            print(f"   - æ€»å¸§æ•°: {frame_count}")
            return output_video_path
        else:
            print(f"âŒ æ ‡æ³¨è§†é¢‘ç”Ÿæˆå¤±è´¥")
            return None


def main():
    """ä¸»å‡½æ•°ï¼šæå–è½¦è¾†è½¨è¿¹å¹¶ä¿å­˜åˆ°CSVæ–‡ä»¶"""
    
    # è¾“å…¥è§†é¢‘è·¯å¾„
    video_path = '/home/lumos/Documents/traffic_analysis/data/raw_videos/traffic_video.mp4'
    
    # è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰æ–‡ä»¶ä½ç½®ï¼‰
    current_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(current_dir, '../data/processed')
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, 'trajectories_raw.csv')
    
    # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    output_path = os.path.abspath(output_path)
    
    print("=" * 60)
    print("          è½¦è¾†è½¨è¿¹æå–ç¨‹åº")
    print("=" * 60)
    print(f"\nğŸ“¹ è¾“å…¥è§†é¢‘: {video_path}")
    print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {os.path.dirname(output_path)}")
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"\nâŒ é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨!")
        print(f"   è·¯å¾„: {video_path}")
        return
    
    # åˆ›å»ºè·Ÿè¸ªå™¨
    print(f"\nğŸ”§ åˆå§‹åŒ–è½¦è¾†è·Ÿè¸ªå™¨...")
    tracker = VehicleTracker()
    
    # æ ¹æ®è§†é¢‘é•¿åº¦é€‰æ‹©å¤„ç†æ¨¡å¼
    import cv2
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    cap.release()
    
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: æ—¶é•¿ {duration/60:.1f} åˆ†é’Ÿ")
    
    # é€‰æ‹©å¤„ç†æ¨¡å¼
    if duration > 10 * 60:  # è¶…è¿‡10åˆ†é’Ÿ
        print("âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼å¤„ç†é•¿è§†é¢‘...")
        trajectories_df = tracker.process_video_fast(video_path, output_path)
    elif duration > 2 * 60:  # 2-10åˆ†é’Ÿ
        print("âš–ï¸ ä½¿ç”¨å¹³è¡¡æ¨¡å¼...")
        trajectories_df = tracker.process_video_balanced(video_path, output_path)
    else:  # çŸ­è§†é¢‘
        print("ğŸ“ ä½¿ç”¨æ ‡å‡†æ¨¡å¼...")
        trajectories_df = tracker.process_video(video_path, output_path)
    
    # æ˜¾ç¤ºç»“æœ
    if trajectories_df.empty:
        print("\nâŒ æ²¡æœ‰æå–åˆ°è½¨è¿¹æ•°æ®ï¼Œè¯·æ£€æŸ¥:")
        print("   1. è§†é¢‘ä¸­æ˜¯å¦æœ‰è½¦è¾†")
        print("   2. ç½®ä¿¡åº¦é˜ˆå€¼æ˜¯å¦è®¾ç½®è¿‡é«˜")
        print("   3. è½¦è¾†ç±»åˆ«è®¾ç½®æ˜¯å¦æ­£ç¡®")
    else:
        print("\n" + "=" * 60)
        print("âœ… è½¨è¿¹æå–å®Œæˆ!")
        print("=" * 60)
        print(f"\nğŸ“Š ç»“æœç»Ÿè®¡:")
        print(f"   - è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
        print(f"   - æ€»è½¨è¿¹ç‚¹æ•°: {len(trajectories_df)}")
        print(f"   - å”¯ä¸€è½¦è¾†æ•°: {trajectories_df['track_id'].nunique()}")
        print(f"   - æ—¶é—´èŒƒå›´: {trajectories_df['time'].min():.2f} - {trajectories_df['time'].max():.2f} ç§’")
        print(f"   - æ—¶é—´è·¨åº¦: {(trajectories_df['time'].max() - trajectories_df['time'].min())/60:.2f} åˆ†é’Ÿ")
        
        # è½¦è¾†ç±»å‹ç»Ÿè®¡
        if 'vehicle_type' in trajectories_df.columns:
            vehicle_type_counts = trajectories_df['vehicle_type'].value_counts()
            print(f"\nğŸš— è½¦è¾†ç±»å‹åˆ†å¸ƒ:")
            for vtype, count in vehicle_type_counts.items():
                percentage = count / len(trajectories_df) * 100
                print(f"   - {vtype}: {count} ä¸ªè½¨è¿¹ç‚¹ ({percentage:.1f}%)")
        
        # æ‘˜è¦æ–‡ä»¶è·¯å¾„
        summary_path = output_path.replace('.csv', '_summary.txt')
        if os.path.exists(summary_path):
            print(f"\nğŸ“„ æ•°æ®æ‘˜è¦: {summary_path}")
        
        # ç”Ÿæˆæ ‡æ³¨è§†é¢‘
        print(f"\nğŸ¬ æ˜¯å¦ç”Ÿæˆæ ‡æ³¨è§†é¢‘? (éœ€è¦é‡æ–°å¤„ç†è§†é¢‘ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´)")
        print(f"   æ­£åœ¨ç”Ÿæˆæ ‡æ³¨è§†é¢‘...")
        
        # è®¾ç½®æ ‡æ³¨è§†é¢‘è¾“å‡ºè·¯å¾„
        video_dir = os.path.dirname(video_path)
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        annotated_video_path = os.path.join(
            os.path.dirname(output_path), 
            f"{video_name}_annotated.mp4"
        )
        annotated_video_path = os.path.abspath(annotated_video_path)
        
        # ç”Ÿæˆæ ‡æ³¨è§†é¢‘
        annotated_video = tracker.generate_annotated_video(
            video_path=video_path,
            trajectories_df=trajectories_df,
            output_video_path=annotated_video_path,
            show_track_id=True,
            show_vehicle_type=True,
            show_confidence=True
        )
        
        if annotated_video:
            print(f"\nğŸ“¹ æ ‡æ³¨è§†é¢‘å·²ä¿å­˜: {annotated_video}")
        
        print(f"\nğŸ’¡ æç¤º: å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½æ•°æ®:")
        print(f"   import pandas as pd")
        print(f"   df = pd.read_csv('{output_path}')")


if __name__ == "__main__":
    main()
