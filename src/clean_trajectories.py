"""
è½¨è¿¹æ•°æ®æ¸…æ´—è„šæœ¬
================
é’ˆå¯¹ `trajectories_raw_video1/2.csv` ä¸­å­˜åœ¨çš„å¼‚å¸¸çºµå‘åæ ‡ã€çŸ­ç¢è½¨è¿¹ã€
å™ªå£°è¾ƒå¤§çš„å®šä½ç­‰é—®é¢˜ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
1. è¡¥é½ä¸–ç•Œåæ ‡ (x_world, y_world)
2. è¿‡æ»¤è¶…å‡ºé“è·¯èŒƒå›´å’Œå« NaN/Inf çš„ç‚¹
3. åˆ é™¤è½¨è¿¹ç‚¹æ•°è¿‡å°‘æˆ–ç¬é—´è·³å˜è¿‡å¤§çš„è½¨è¿¹
4. å›ºå®šæ—¶é—´æ­¥é•¿é‡é‡‡æ · + çº¿æ€§æ’å€¼
5. æ»šåŠ¨å¹³å‡å¹³æ»‘
6. ä¸€ç»´å¸¸é€Ÿå¡å°”æ›¼æ»¤æ³¢
æ¸…æ´—åçš„æ•°æ®å°†åˆ†åˆ«ä¿å­˜ä¸º `trajectories_cleaned_videoX.csv`ã€‚
"""

from __future__ import annotations

import argparse
from pathlib import Path
from typing import List, Sequence

import numpy as np
import pandas as pd

from coordinate_transformation import CoordinateTransformer
from config import ROAD_CONFIG


LANE_MAPPING = {
    "lan1": 1,
    "lane1": 1,
    "1": 1,
    "lan2": 2,
    "lane2": 2,
    "2": 2,
    "lan3": 3,
    "lane3": 3,
    "3": 3,
    "non-motor": 0,
    "non_motor": 0,
    "nonmotor": 0,
    "0": 0,
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="æ¸…æ´—è½¨è¿¹æ•°æ®")
    parser.add_argument(
        "--inputs",
        nargs="+",
        default=[
            "/home/lumos/Documents/traffic_analysis/data/processed/trajectories_raw_video1.csv",
            "/home/lumos/Documents/traffic_analysis/data/processed/trajectories_raw_video2.csv",
        ],
        help="è¾“å…¥ CSV è·¯å¾„ï¼Œé»˜è®¤åŒ…å« video1 å’Œ video2ã€‚",
    )
    parser.add_argument(
        "--output-dir",
        default="/home/lumos/Documents/traffic_analysis/data/processed",
        help="è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸åŸæ•°æ®ç›¸åŒã€‚",
    )
    parser.add_argument(
        "--dt",
        type=float,
        default=0.2,
        help="é‡é‡‡æ ·æ—¶é—´æ­¥é•¿ (ç§’)ã€‚",
    )
    parser.add_argument(
        "--min-points",
        type=int,
        default=15,
        help="è½¨è¿¹æœ€å°ç‚¹æ•°ï¼Œå°äºè¯¥å€¼å°†è¢«ä¸¢å¼ƒã€‚",
    )
    parser.add_argument(
        "--max-jump",
        type=float,
        default=5.0,
        help="å•æ­¥å…è®¸çš„æœ€å¤§ä½ç§» (ç±³)ï¼Œè¶…è¿‡è§†ä¸ºå¼‚å¸¸ç‚¹ã€‚",
    )
    return parser.parse_args()


def load_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        raise FileNotFoundError(path)
    df = pd.read_csv(path)
    df["source_file"] = path.name
    print(f"âœ… è¯»å– {path.name}: {len(df)} è¡Œ, {df['track_id'].nunique()} æ¡è½¨è¿¹")
    return df


def ensure_world_coords(df: pd.DataFrame, transformer: CoordinateTransformer) -> pd.DataFrame:
    if {"x_world", "y_world"}.issubset(df.columns):
        return df
    print("ğŸ”„ æœªæ‰¾åˆ°ä¸–ç•Œåæ ‡ï¼Œæ‰§è¡Œé€è§†å˜æ¢...")
    world = transformer.pixel_to_world(df[["x", "y"]].values)
    df["x_world"] = world[:, 0]
    df["y_world"] = world[:, 1]
    return df


def clean_range(df: pd.DataFrame, margin: float = 5.0) -> pd.DataFrame:
    lower = -margin
    upper = ROAD_CONFIG.get("length", 0) + margin
    before = len(df)
    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=["x_world", "time"])
    df = df[(df["x_world"] >= lower) & (df["x_world"] <= upper)]
    removed = before - len(df)
    if removed:
        print(f"ğŸ§¹ å»é™¤è¶Šç•Œ/ç¼ºå¤±ç‚¹ {removed} è¡Œ")
    return df


def standardize_lane(df: pd.DataFrame) -> pd.DataFrame:
    if "lane" not in df.columns:
        df["lane_num"] = 0
    else:
        df["lane_num"] = (
            df["lane"].astype(str).str.lower().map(LANE_MAPPING).fillna(0).astype(int)
        )
    return df


def basic_filter(df: pd.DataFrame, min_points: int, max_jump: float) -> pd.DataFrame:
    groups: List[pd.DataFrame] = []
    for tid, g in df.groupby("track_id"):
        g = g.sort_values("time")
        if len(g) < min_points:
            continue
        jumps = g["x_world"].diff().abs()
        g = g[(jumps <= max_jump) | jumps.isna()]
        if len(g) < min_points:
            continue
        groups.append(g)
    if not groups:
        return pd.DataFrame(columns=df.columns)
    result = pd.concat(groups, ignore_index=True)
    print(f"ğŸ§½ åŸºç¡€è¿‡æ»¤å {len(result)} è¡Œ, {result['track_id'].nunique()} æ¡è½¨è¿¹")
    return result


def resample_tracks(df: pd.DataFrame, dt: float) -> pd.DataFrame:
    resampled = []
    for tid, g in df.groupby("track_id"):
        g = g.sort_values("time")
        if len(g) < 2:
            continue
        start, end = g["time"].iloc[0], g["time"].iloc[-1]
        if end - start < dt:
            continue
        new_times = np.arange(start, end + 1e-9, dt)
        new_x = np.interp(new_times, g["time"], g["x_world"])
        new_y = (
            np.interp(new_times, g["time"], g["y_world"])
            if "y_world" in g.columns
            else np.zeros_like(new_times)
        )
        lane_num = g["lane_num"].iloc[0] if "lane_num" in g else 0
        lane_label = g["lane"].iloc[0] if "lane" in g else str(lane_num)
        vehicle_type = g["vehicle_type"].iloc[0] if "vehicle_type" in g else "car"
        src = g["source_file"].iloc[0]

        resampled.append(
            pd.DataFrame(
                {
                    "track_id": tid,
                    "time": new_times,
                    "x_world": new_x,
                    "y_world": new_y,
                    "lane": lane_label,
                    "lane_num": lane_num,
                    "vehicle_type": vehicle_type,
                    "source_file": src,
                }
            )
        )
    if not resampled:
        return pd.DataFrame(columns=["track_id", "time", "x_world", "y_world"])
    result = pd.concat(resampled, ignore_index=True)
    print(f"ğŸ” é‡é‡‡æ · (dt={dt}s) å {len(result)} è¡Œ, {result['track_id'].nunique()} æ¡è½¨è¿¹")
    return result


def smooth_tracks(df: pd.DataFrame, window: int = 5) -> pd.DataFrame:
    smoothed = []
    for tid, g in df.groupby("track_id"):
        g = g.sort_values("time")
        g["x_world"] = g["x_world"].rolling(window, center=True, min_periods=1).mean()
        smoothed.append(g)
    return pd.concat(smoothed, ignore_index=True)


def kalman_filter(df: pd.DataFrame, dt: float) -> pd.DataFrame:
    filtered = []
    F = np.array([[1, dt], [0, 1]])
    H = np.array([[1, 0]])
    q = 0.5
    r = 1.0
    Q = q * np.array([[0.25 * dt**4, 0.5 * dt**3], [0.5 * dt**3, dt**2]])
    R = np.array([[r]])

    for tid, g in df.groupby("track_id"):
        g = g.sort_values("time").copy()
        z = g["x_world"].values
        x_state = np.array([z[0], 0.0])
        P = np.eye(2)
        outputs = []
        for measurement in z:
            x_state = F @ x_state
            P = F @ P @ F.T + Q

            y = measurement - (H @ x_state)
            S = H @ P @ H.T + R
            K = P @ H.T @ np.linalg.inv(S)
            x_state = x_state + (K @ y).flatten()
            P = (np.eye(2) - K @ H) @ P

            outputs.append(x_state[0])

        g["x_world"] = outputs
        filtered.append(g)

    result = pd.concat(filtered, ignore_index=True)
    print("ğŸ¤– å¡å°”æ›¼æ»¤æ³¢å®Œæˆ")
    return result


def process_file(path: Path, args: argparse.Namespace, transformer: CoordinateTransformer) -> Path:
    df = load_csv(path)
    df = ensure_world_coords(df, transformer)
    df = clean_range(df)
    df = standardize_lane(df)
    df = basic_filter(df, args.min_points, args.max_jump)
    df = resample_tracks(df, args.dt)
    df = smooth_tracks(df)
    df = kalman_filter(df, args.dt)

    output_path = Path(args.output_dir) / path.name.replace("raw", "cleaned")
    df.to_csv(output_path, index=False)
    print(f"ğŸ’¾ æ¸…æ´—ç»“æœå·²ä¿å­˜: {output_path} ({len(df)} è¡Œ)")
    return output_path


def main():
    args = parse_args()
    transformer = CoordinateTransformer()
    output_files = []
    for input_path in args.inputs:
        output_files.append(process_file(Path(input_path), args, transformer))

    print("\n=== æ¸…æ´—å®Œæˆ ===")
    for file in output_files:
        print(f" - {file}")


if __name__ == "__main__":
    main()
